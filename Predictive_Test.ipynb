{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Albert-26/python-fundamentals/blob/main/Predictive_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMhwbz02J2u1",
        "outputId": "793fa364-fff7-4d61-e5b7-46ebf3f19292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7000 entries, 0 to 6999\n",
            "Data columns (total 61 columns):\n",
            " #   Column                                        Non-Null Count  Dtype  \n",
            "---  ------                                        --------------  -----  \n",
            " 0   ID                                            7000 non-null   int64  \n",
            " 1   source                                        7000 non-null   object \n",
            " 2   name                                          6999 non-null   object \n",
            " 3   description                                   6943 non-null   object \n",
            " 4   neighborhood_overview                         5177 non-null   object \n",
            " 5   host_name                                     7000 non-null   object \n",
            " 6   host_since                                    7000 non-null   object \n",
            " 7   host_location                                 5720 non-null   object \n",
            " 8   host_about                                    4730 non-null   object \n",
            " 9   host_response_time                            7000 non-null   object \n",
            " 10  host_response_rate                            7000 non-null   object \n",
            " 11  host_acceptance_rate                          6937 non-null   object \n",
            " 12  host_is_superhost                             7000 non-null   object \n",
            " 13  host_neighbourhood                            3540 non-null   object \n",
            " 14  host_listings_count                           7000 non-null   int64  \n",
            " 15  host_verifications                            7000 non-null   object \n",
            " 16  host_has_profile_pic                          7000 non-null   object \n",
            " 17  host_identity_verified                        7000 non-null   object \n",
            " 18  neighbourhood                                 5177 non-null   object \n",
            " 19  neighbourhood_cleansed                        6892 non-null   object \n",
            " 20  latitude                                      7000 non-null   float64\n",
            " 21  longitude                                     7000 non-null   float64\n",
            " 22  property_type                                 6916 non-null   object \n",
            " 23  room_type                                     6866 non-null   object \n",
            " 24  accommodates                                  7000 non-null   int64  \n",
            " 25  bathrooms                                     6994 non-null   object \n",
            " 26  bedrooms                                      6622 non-null   float64\n",
            " 27  beds                                          6928 non-null   float64\n",
            " 28  amenities                                     7000 non-null   object \n",
            " 29  minimum_nights                                7000 non-null   int64  \n",
            " 30  maximum_nights                                7000 non-null   int64  \n",
            " 31  minimum_minimum_nights                        6955 non-null   float64\n",
            " 32  maximum_minimum_nights                        7000 non-null   int64  \n",
            " 33  minimum_maximum_nights                        7000 non-null   int64  \n",
            " 34  maximum_maximum_nights                        6955 non-null   float64\n",
            " 35  minimum_nights_avg_ntm                        7000 non-null   float64\n",
            " 36  maximum_nights_avg_ntm                        7000 non-null   float64\n",
            " 37  has_availability                              7000 non-null   object \n",
            " 38  availability_30                               7000 non-null   int64  \n",
            " 39  availability_60                               7000 non-null   int64  \n",
            " 40  availability_90                               7000 non-null   int64  \n",
            " 41  availability_365                              6953 non-null   float64\n",
            " 42  number_of_reviews                             7000 non-null   int64  \n",
            " 43  number_of_reviews_ltm                         7000 non-null   int64  \n",
            " 44  number_of_reviews_l30d                        7000 non-null   int64  \n",
            " 45  first_review                                  7000 non-null   object \n",
            " 46  last_review                                   7000 non-null   object \n",
            " 47  review_scores_rating                          7000 non-null   float64\n",
            " 48  review_scores_accuracy                        6978 non-null   float64\n",
            " 49  review_scores_cleanliness                     6978 non-null   float64\n",
            " 50  review_scores_checkin                         6978 non-null   float64\n",
            " 51  review_scores_communication                   6978 non-null   float64\n",
            " 52  review_scores_location                        6978 non-null   float64\n",
            " 53  review_scores_value                           6978 non-null   float64\n",
            " 54  instant_bookable                              7000 non-null   object \n",
            " 55  calculated_host_listings_count                7000 non-null   int64  \n",
            " 56  calculated_host_listings_count_entire_homes   7000 non-null   int64  \n",
            " 57  calculated_host_listings_count_private_rooms  7000 non-null   int64  \n",
            " 58  calculated_host_listings_count_shared_rooms   7000 non-null   int64  \n",
            " 59  reviews_per_month                             7000 non-null   float64\n",
            " 60  price                                         7000 non-null   object \n",
            "dtypes: float64(17), int64(17), object(27)\n",
            "memory usage: 3.3+ MB\n"
          ]
        }
      ],
      "source": [
        "## Task 2, Question 1 Code Here\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Dataset/train.csv\")\n",
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5MG4GzjKNIT",
        "outputId": "d2399ca9-2cfe-42b1-9f41-45f5ac36f827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 60 columns):\n",
            " #   Column                                        Non-Null Count  Dtype  \n",
            "---  ------                                        --------------  -----  \n",
            " 0   ID                                            3000 non-null   int64  \n",
            " 1   source                                        3000 non-null   object \n",
            " 2   name                                          3000 non-null   object \n",
            " 3   description                                   2969 non-null   object \n",
            " 4   neighborhood_overview                         1576 non-null   object \n",
            " 5   host_name                                     3000 non-null   object \n",
            " 6   host_since                                    3000 non-null   object \n",
            " 7   host_location                                 2230 non-null   object \n",
            " 8   host_about                                    1559 non-null   object \n",
            " 9   host_response_time                            2263 non-null   object \n",
            " 10  host_response_rate                            2263 non-null   object \n",
            " 11  host_acceptance_rate                          2342 non-null   object \n",
            " 12  host_is_superhost                             2998 non-null   object \n",
            " 13  host_neighbourhood                            934 non-null    object \n",
            " 14  host_listings_count                           3000 non-null   float64\n",
            " 15  host_verifications                            3000 non-null   object \n",
            " 16  host_has_profile_pic                          3000 non-null   object \n",
            " 17  host_identity_verified                        3000 non-null   object \n",
            " 18  neighbourhood                                 1576 non-null   object \n",
            " 19  neighbourhood_cleansed                        2958 non-null   object \n",
            " 20  latitude                                      3000 non-null   float64\n",
            " 21  longitude                                     3000 non-null   float64\n",
            " 22  property_type                                 2961 non-null   object \n",
            " 23  room_type                                     2959 non-null   object \n",
            " 24  accommodates                                  3000 non-null   int64  \n",
            " 25  bathrooms                                     3000 non-null   object \n",
            " 26  bedrooms                                      2940 non-null   float64\n",
            " 27  beds                                          2988 non-null   float64\n",
            " 28  amenities                                     3000 non-null   object \n",
            " 29  minimum_nights                                3000 non-null   int64  \n",
            " 30  maximum_nights                                3000 non-null   int64  \n",
            " 31  minimum_minimum_nights                        2990 non-null   float64\n",
            " 32  maximum_minimum_nights                        3000 non-null   int64  \n",
            " 33  minimum_maximum_nights                        3000 non-null   int64  \n",
            " 34  maximum_maximum_nights                        2990 non-null   float64\n",
            " 35  minimum_nights_avg_ntm                        3000 non-null   float64\n",
            " 36  maximum_nights_avg_ntm                        3000 non-null   float64\n",
            " 37  has_availability                              3000 non-null   object \n",
            " 38  availability_30                               3000 non-null   int64  \n",
            " 39  availability_60                               3000 non-null   int64  \n",
            " 40  availability_90                               3000 non-null   int64  \n",
            " 41  availability_365                              2980 non-null   float64\n",
            " 42  number_of_reviews                             3000 non-null   int64  \n",
            " 43  number_of_reviews_ltm                         3000 non-null   int64  \n",
            " 44  number_of_reviews_l30d                        3000 non-null   int64  \n",
            " 45  first_review                                  2737 non-null   object \n",
            " 46  last_review                                   2737 non-null   object \n",
            " 47  review_scores_rating                          2737 non-null   float64\n",
            " 48  review_scores_accuracy                        2701 non-null   float64\n",
            " 49  review_scores_cleanliness                     2701 non-null   float64\n",
            " 50  review_scores_checkin                         2700 non-null   float64\n",
            " 51  review_scores_communication                   2700 non-null   float64\n",
            " 52  review_scores_location                        2700 non-null   float64\n",
            " 53  review_scores_value                           2700 non-null   float64\n",
            " 54  instant_bookable                              3000 non-null   object \n",
            " 55  calculated_host_listings_count                3000 non-null   int64  \n",
            " 56  calculated_host_listings_count_entire_homes   3000 non-null   int64  \n",
            " 57  calculated_host_listings_count_private_rooms  3000 non-null   int64  \n",
            " 58  calculated_host_listings_count_shared_rooms   3000 non-null   int64  \n",
            " 59  reviews_per_month                             2737 non-null   float64\n",
            "dtypes: float64(18), int64(16), object(26)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ],
      "source": [
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Dataset/test.csv\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k9nZ-ZtKNLI",
        "outputId": "766c89ab-ddfc-4388-e34e-5e309167da87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the Number of NaN values per column in train dataset:\n",
            "name has 1 missing points which is 0.01% as missing value\n",
            "description has 57 missing points which is 0.81% as missing value\n",
            "neighborhood_overview has 1823 missing points which is 26.04% as missing value\n",
            "host_location has 1280 missing points which is 18.29% as missing value\n",
            "host_about has 2270 missing points which is 32.43% as missing value\n",
            "host_acceptance_rate has 63 missing points which is 0.9% as missing value\n",
            "host_neighbourhood has 3460 missing points which is 49.43% as missing value\n",
            "neighbourhood has 1823 missing points which is 26.04% as missing value\n",
            "neighbourhood_cleansed has 108 missing points which is 1.54% as missing value\n",
            "property_type has 84 missing points which is 1.2% as missing value\n",
            "room_type has 134 missing points which is 1.91% as missing value\n",
            "bathrooms has 6 missing points which is 0.09% as missing value\n",
            "bedrooms has 378 missing points which is 5.4% as missing value\n",
            "beds has 72 missing points which is 1.03% as missing value\n",
            "minimum_minimum_nights has 45 missing points which is 0.64% as missing value\n",
            "maximum_maximum_nights has 45 missing points which is 0.64% as missing value\n",
            "availability_365 has 47 missing points which is 0.67% as missing value\n",
            "review_scores_accuracy has 22 missing points which is 0.31% as missing value\n",
            "review_scores_cleanliness has 22 missing points which is 0.31% as missing value\n",
            "review_scores_checkin has 22 missing points which is 0.31% as missing value\n",
            "review_scores_communication has 22 missing points which is 0.31% as missing value\n",
            "review_scores_location has 22 missing points which is 0.31% as missing value\n",
            "review_scores_value has 22 missing points which is 0.31% as missing value\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "column_name = train_df.columns\n",
        "print('Checking the Number of NaN values per column in train dataset:')\n",
        "for col in column_name:\n",
        "    if int(train_df[col].isnull().sum()) > 0:  \n",
        "      print(f'{col} has {train_df[col].isnull().sum()} missing points which is {np.round((train_df[col].isnull().sum()/7000)*100, 2)}% as missing value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxmbXLVUKNNu",
        "outputId": "35cff65f-be1b-4d8b-b6d9-ab3f2876dadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import datetime\n",
        "import re\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from numpy import absolute\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import missingno as msno\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU6RyqvbKNQe",
        "outputId": "fd88d96a-12d7-4bd1-b181-3fabd7b73d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (1.7.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.24.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Install xgboost\n",
        "!pip install xgboost\n",
        "\n",
        "# Rest of the code\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Continue with the rest of your code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3k5ptOe8KNTI"
      },
      "outputs": [],
      "source": [
        "train_df = pd.concat([train_df, test_df]) #merging test and train data for imputing all the missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IUOCwLLJKNVg"
      },
      "outputs": [],
      "source": [
        "#removing $ sign from the price column\n",
        "train_df['price'] = train_df['price'].apply(lambda x: x.replace('$', '').replace(',', '') if isinstance(x, str) else x).astype(float)\n",
        "\n",
        "# removing % sign from the host_response_rate column\n",
        "train_df['host_response_rate'] = train_df['host_response_rate'].apply(lambda x: x.replace('%', '').replace(',', '') if isinstance(x, str) else x).astype(float)\n",
        "\n",
        "# removing % sign from the host_response_rate column\n",
        "train_df['host_acceptance_rate'] = train_df['host_acceptance_rate'].apply(lambda x: x.replace('%', '').replace(',', '')  if isinstance(x, str) else x).astype(float)\n",
        "\n",
        "\n",
        "#extracting numberical values only from the bathroom column\n",
        "train_df['bathrooms'] = train_df['bathrooms'].str.extract('(\\d+)')\n",
        "# imputing 0.5 in NaN as we have 'half shared bathrooms' which is not extracted from the column \n",
        "train_df['bathrooms'] = train_df['bathrooms'].fillna(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_rIBvFaIKNXh"
      },
      "outputs": [],
      "source": [
        "test_df = train_df[7000::]\n",
        "train_df = train_df[:7000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VN31FITZKNeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a00583-17f3-4699-8826-1a32a9cea0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2d53ec538108>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['name_length'] = data['name'].fillna('').apply(lambda x: len(x.split()))                                  #word count of the name\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# Function for feature engineering\n",
        "def feature_engineering(data):\n",
        "    data['name_length'] = data['name'].fillna('').apply(lambda x: len(x.split()))                                  #word count of the name\n",
        "    data['desc_length'] = data['description'].fillna('').apply(lambda x: len(x.split()))                           #word count of the description\n",
        "    data['neighborhood_overview_length'] = data['neighborhood_overview'].fillna('').apply(lambda x: len(x.split()))#word count of the neighbourhood overview\n",
        "    data['host_about_length'] = data['host_about'].fillna('').apply(lambda x: len(x.split()))                       #word count of the host about\n",
        "    data['total_verification'] = data['host_verifications'].fillna('').apply(lambda x: len(x.split()))              #number of verification of host\n",
        "    data['total_amenities'] = data['amenities'].fillna('').apply(lambda x: len(x.split()))                          #total number of amenties provided by the host\n",
        "    data['host_since'] = pd.to_datetime(data['host_since'])                                                          #converting into daytime format\n",
        "    data['first_review'] = pd.to_datetime(data['first_review'])                                                      #converting into daytime format\n",
        "    data['last_review'] = pd.to_datetime(data['last_review'])                                                        #converting into daytime format\n",
        "    today = datetime.datetime.today()\n",
        "    data['number_of_days_as_host'] = (today - data['host_since']).dt.days                                           #total number of days as host till today\n",
        "    data['number_of_days_last_review'] = (today - data['last_review']).dt.days                                      #total number of day from last review till today\n",
        "    data['number_of_days_first_review'] = (today - data['first_review']).dt.days                                    #total number of day from first review till today\n",
        "    data['diff_in_last_&_first_review'] = data['number_of_days_first_review'] - data['number_of_days_last_review']  #days difference between first and last review\n",
        "    data = data.drop(['host_since', 'first_review', 'last_review'], axis=1)\n",
        "    data['neighbourhood'] = data['neighbourhood'].fillna('').apply(lambda x: (x.split(',')[0]))\n",
        "    data['host_location'] = data['host_location'].fillna('').apply(lambda x: (x.split(',')[0]))\n",
        "    return data\n",
        "\n",
        "# Call the feature_engineering function for train and test datasets\n",
        "train_df = feature_engineering(train_df)\n",
        "test_df = feature_engineering(test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-9dqWQxwKNj1"
      },
      "outputs": [],
      "source": [
        "train_df['name'] = train_df['name'].fillna('missing')\n",
        "train_df['description'] = train_df['description'].fillna('missing')\n",
        "train_df['neighborhood_overview'] = train_df['neighborhood_overview'].fillna('missing')\n",
        "train_df['host_name'] = train_df['host_name'].fillna('missing')\n",
        "train_df['host_location'] = train_df['host_location'].fillna(train_df['host_location'].mode()[0])\n",
        "train_df['host_about'] = train_df['host_about'].fillna('missing')\n",
        "train_df['host_response_time'] = train_df['host_response_time'].fillna(train_df['host_response_time'].mode()[0])\n",
        "train_df['host_response_rate'] = train_df['host_response_rate'].fillna(train_df['host_response_rate'].mean())\n",
        "train_df['host_acceptance_rate'] = train_df['host_acceptance_rate'].fillna(train_df['host_acceptance_rate'].mean())\n",
        "train_df['host_is_superhost'] = train_df['host_is_superhost'].fillna(train_df['host_is_superhost'].mode()[0])\n",
        "train_df['host_neighbourhood'] = train_df['host_neighbourhood'].fillna(train_df['host_neighbourhood'].mode()[0])\n",
        "train_df['host_listings_count'] = train_df['host_listings_count'].fillna(train_df['host_listings_count'].mean())\n",
        "train_df['host_verifications'] = train_df['host_verifications'].fillna(train_df['host_verifications'].mode()[0])\n",
        "train_df['host_has_profile_pic'] = train_df['host_has_profile_pic'].fillna(train_df['host_has_profile_pic'].mode()[0])\n",
        "train_df['host_identity_verified'] = train_df['host_identity_verified'].fillna(train_df['host_identity_verified'].mode()[0])\n",
        "train_df['neighbourhood'] = train_df['neighbourhood'].fillna(train_df['neighbourhood'].mode()[0])\n",
        "train_df['neighbourhood_cleansed'] = train_df['neighbourhood_cleansed'].fillna(train_df['neighbourhood_cleansed'].mode()[0])\n",
        "train_df['latitude'] = train_df['latitude'].fillna(train_df['latitude'].mean())\n",
        "train_df['longitude'] = train_df['longitude'].fillna(train_df['longitude'].mean())\n",
        "train_df['property_type'] = train_df['property_type'].fillna(train_df['property_type'].mode()[0])\n",
        "train_df['room_type'] = train_df['room_type'].fillna(train_df['room_type'].mode()[0])\n",
        "train_df['accommodates'] = train_df['accommodates'].fillna(train_df['accommodates'].mean())\n",
        "train_df['bathrooms'] = pd.to_numeric(train_df['bathrooms'], errors='coerce')\n",
        "train_df['bathrooms'] = train_df['bathrooms'].fillna(train_df['bathrooms'].mean())\n",
        "train_df['bedrooms'] = train_df['bedrooms'].fillna(train_df['bedrooms'].mean())\n",
        "train_df['beds'] = train_df['beds'].fillna(train_df['beds'].mean())\n",
        "train_df['amenities'] = train_df['amenities'].fillna('missing')\n",
        "train_df['minimum_nights'] = train_df['minimum_nights'].fillna(train_df['minimum_nights'].mean())\n",
        "train_df['maximum_nights'] = train_df['maximum_nights'].fillna(train_df['maximum_nights'].mean())\n",
        "train_df['minimum_minimum_nights'] = train_df['minimum_minimum_nights'].fillna(train_df['minimum_minimum_nights'].mean())\n",
        "train_df['maximum_minimum_nights'] = train_df['maximum_minimum_nights'].fillna(train_df['maximum_minimum_nights'].mean())\n",
        "train_df['minimum_maximum_nights'] = train_df['minimum_maximum_nights'].fillna(train_df['minimum_maximum_nights'].mean())\n",
        "train_df['maximum_maximum_nights'] = train_df['maximum_maximum_nights'].fillna(train_df['maximum_maximum_nights'].mean())\n",
        "train_df['minimum_nights_avg_ntm'] = train_df['minimum_nights_avg_ntm'].fillna(train_df['minimum_nights_avg_ntm'].mean())\n",
        "train_df['maximum_nights_avg_ntm'] = train_df['maximum_nights_avg_ntm'].fillna(train_df['maximum_nights_avg_ntm'].mean())\n",
        "train_df['has_availability'] = train_df['has_availability'].fillna(train_df['has_availability'].mode()[0])\n",
        "train_df['availability_30'] = train_df['availability_30'].fillna(train_df['availability_30'].mean())\n",
        "train_df['availability_60'] = train_df['availability_60'].fillna(train_df['availability_60'].mean())\n",
        "train_df['availability_90'] = train_df['availability_90'].fillna(train_df['availability_90'].mean())\n",
        "train_df['availability_365'] = train_df['availability_365'].fillna(train_df['availability_365'].mean())\n",
        "train_df['number_of_reviews'] = train_df['number_of_reviews'].fillna(train_df['number_of_reviews'].mean())\n",
        "train_df['number_of_reviews_ltm'] = train_df['number_of_reviews_ltm'].fillna(train_df['number_of_reviews_ltm'].mean())\n",
        "train_df['number_of_reviews_l30d'] = train_df['number_of_reviews_l30d'].fillna(train_df['number_of_reviews_l30d'].mean())\n",
        "train_df['review_scores_rating'] = train_df['review_scores_rating'].fillna(train_df['review_scores_rating'].mean())\n",
        "train_df['review_scores_accuracy'] = train_df['review_scores_accuracy'].fillna(train_df['review_scores_accuracy'].mean())\n",
        "train_df['review_scores_cleanliness'] = train_df['review_scores_cleanliness'].fillna(train_df['review_scores_cleanliness'].mean())\n",
        "train_df['review_scores_checkin'] = train_df['review_scores_checkin'].fillna(train_df['review_scores_checkin'].mean())\n",
        "train_df['review_scores_communication'] = train_df['review_scores_communication'].fillna(train_df['review_scores_communication'].mean())\n",
        "train_df['review_scores_location'] = train_df['review_scores_location'].fillna(train_df['review_scores_location'].mean())\n",
        "train_df['review_scores_value'] = train_df['review_scores_value'].fillna(train_df['review_scores_accuracy'].mean())\n",
        "train_df['instant_bookable'] = train_df['instant_bookable'].fillna(train_df['instant_bookable'].mode()[0])\n",
        "train_df['calculated_host_listings_count'] = train_df['calculated_host_listings_count'].fillna(train_df['calculated_host_listings_count'].mean())\n",
        "train_df['calculated_host_listings_count_entire_homes'] = train_df['calculated_host_listings_count_entire_homes'].fillna(train_df['calculated_host_listings_count_entire_homes'].mean())\n",
        "train_df['calculated_host_listings_count_private_rooms'] = train_df['calculated_host_listings_count_private_rooms'].fillna(train_df['calculated_host_listings_count_private_rooms'].mean())\n",
        "train_df['calculated_host_listings_count_shared_rooms'] = train_df['calculated_host_listings_count_shared_rooms'].fillna(train_df['calculated_host_listings_count_shared_rooms'].mean())\n",
        "train_df['reviews_per_month'] = train_df['reviews_per_month'].fillna(train_df['reviews_per_month'].mean())\n",
        "train_df['reviews_per_month'] = train_df['reviews_per_month'].fillna(train_df['reviews_per_month'].mean())\n",
        "train_df['price'] = train_df['price'].fillna(train_df['price'].mean())\n",
        "train_df['name_length'] = train_df['name_length'].fillna(train_df['name_length'].mean())\n",
        "train_df['desc_length'] = train_df['desc_length'].fillna(train_df['desc_length'].mean())\n",
        "train_df['neighborhood_overview_length'] = train_df['neighborhood_overview_length'].fillna(train_df['neighborhood_overview_length'].mean())\n",
        "train_df['host_about_length'] = train_df['host_about_length'].fillna(train_df['host_about_length'].mean())\n",
        "train_df['total_verification'] = train_df['total_verification'].fillna(train_df['total_verification'].mean())\n",
        "train_df['total_amenities'] = train_df['total_amenities'].fillna(train_df['total_amenities'].mean())\n",
        "train_df['number_of_days_as_host'] = train_df['number_of_days_as_host'].fillna(train_df['number_of_days_as_host'].mean())\n",
        "train_df['number_of_days_last_review'] = train_df['number_of_days_last_review'].fillna(train_df['number_of_days_last_review'].mean())\n",
        "train_df['number_of_days_first_review'] = train_df['number_of_days_first_review'].fillna(train_df['number_of_days_first_review'].mean())\n",
        "train_df['diff_in_last_&_first_review'] = train_df['diff_in_last_&_first_review'].fillna(train_df['diff_in_last_&_first_review'].mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dEnqGbJKNnM",
        "outputId": "61dfba40-6286-41cc-d42b-7c7ce3ea70bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ID', 'source', 'name', 'description', 'neighborhood_overview',\n",
            "       'host_name', 'host_location', 'host_about', 'host_response_time',\n",
            "       'host_response_rate', 'host_acceptance_rate', 'host_is_superhost',\n",
            "       'host_neighbourhood', 'host_listings_count', 'host_verifications',\n",
            "       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n",
            "       'neighbourhood_cleansed', 'latitude', 'longitude', 'property_type',\n",
            "       'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds',\n",
            "       'amenities', 'minimum_nights', 'maximum_nights',\n",
            "       'minimum_minimum_nights', 'maximum_minimum_nights',\n",
            "       'minimum_maximum_nights', 'maximum_maximum_nights',\n",
            "       'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'has_availability',\n",
            "       'availability_30', 'availability_60', 'availability_90',\n",
            "       'availability_365', 'number_of_reviews', 'number_of_reviews_ltm',\n",
            "       'number_of_reviews_l30d', 'review_scores_rating',\n",
            "       'review_scores_accuracy', 'review_scores_cleanliness',\n",
            "       'review_scores_checkin', 'review_scores_communication',\n",
            "       'review_scores_location', 'review_scores_value', 'instant_bookable',\n",
            "       'calculated_host_listings_count',\n",
            "       'calculated_host_listings_count_entire_homes',\n",
            "       'calculated_host_listings_count_private_rooms',\n",
            "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month',\n",
            "       'price', 'name_length', 'desc_length', 'neighborhood_overview_length',\n",
            "       'host_about_length', 'total_verification', 'total_amenities',\n",
            "       'number_of_days_as_host', 'number_of_days_last_review',\n",
            "       'number_of_days_first_review', 'diff_in_last_&_first_review'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "column_names = test_df.columns\n",
        "print(column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LIZ3LrxJKNrP"
      },
      "outputs": [],
      "source": [
        "test_df['name'] = test_df['name'].fillna('missing')\n",
        "test_df['description'] = test_df['description'].fillna('missing')\n",
        "test_df['neighborhood_overview'] = test_df['neighborhood_overview'].fillna('missing')\n",
        "test_df['host_name'] = test_df['host_name'].fillna('missing')\n",
        "test_df['host_location'] = test_df['host_location'].fillna(test_df['host_location'].mode()[0])\n",
        "test_df['host_about'] = test_df['host_about'].fillna('missing')\n",
        "test_df['host_response_time'] = test_df['host_response_time'].fillna(test_df['host_response_time'].mode()[0])\n",
        "test_df['host_response_rate'] = test_df['host_response_rate'].fillna(test_df['host_response_rate'].mean())\n",
        "test_df['host_acceptance_rate'] = test_df['host_acceptance_rate'].fillna(test_df['host_acceptance_rate'].mean())\n",
        "test_df['host_is_superhost'] = test_df['host_is_superhost'].fillna(test_df['host_is_superhost'].mode()[0])\n",
        "test_df['host_neighbourhood'] = test_df['host_neighbourhood'].fillna(test_df['host_neighbourhood'].mode()[0])\n",
        "test_df['host_listings_count'] = test_df['host_listings_count'].fillna(test_df['host_listings_count'].mean())\n",
        "test_df['host_verifications'] = test_df['host_verifications'].fillna(test_df['host_verifications'].mode()[0])\n",
        "test_df['host_has_profile_pic'] = test_df['host_has_profile_pic'].fillna(test_df['host_has_profile_pic'].mode()[0])\n",
        "test_df['host_identity_verified'] = test_df['host_identity_verified'].fillna(test_df['host_identity_verified'].mode()[0])\n",
        "test_df['neighbourhood'] = test_df['neighbourhood'].fillna(test_df['neighbourhood'].mode()[0])\n",
        "test_df['neighbourhood_cleansed'] = test_df['neighbourhood_cleansed'].fillna(test_df['neighbourhood_cleansed'].mode()[0])\n",
        "test_df['latitude'] = test_df['latitude'].fillna(test_df['latitude'].mean())\n",
        "test_df['longitude'] = test_df['longitude'].fillna(test_df['longitude'].mean())\n",
        "test_df['property_type'] = test_df['property_type'].fillna(test_df['property_type'].mode()[0])\n",
        "test_df['room_type'] = test_df['room_type'].fillna(test_df['room_type'].mode()[0])\n",
        "test_df['accommodates'] = test_df['accommodates'].fillna(test_df['accommodates'].mean())\n",
        "test_df['bathrooms'] = pd.to_numeric(test_df['bathrooms'], errors='coerce')\n",
        "test_df['bathrooms'] = test_df['bathrooms'].fillna(test_df['bathrooms'].mean())\n",
        "test_df['bedrooms'] = test_df['bedrooms'].fillna(test_df['bedrooms'].mean())\n",
        "test_df['beds'] = test_df['beds'].fillna(test_df['beds'].mean())\n",
        "test_df['amenities'] = test_df['amenities'].fillna('missing')\n",
        "test_df['minimum_nights'] = test_df['minimum_nights'].fillna(test_df['minimum_nights'].mean())\n",
        "test_df['maximum_nights'] = test_df['maximum_nights'].fillna(test_df['maximum_nights'].mean())\n",
        "test_df['minimum_minimum_nights'] = test_df['minimum_minimum_nights'].fillna(test_df['minimum_minimum_nights'].mean())\n",
        "test_df['maximum_minimum_nights'] = test_df['maximum_minimum_nights'].fillna(test_df['maximum_minimum_nights'].mean())\n",
        "test_df['minimum_maximum_nights'] = test_df['minimum_maximum_nights'].fillna(test_df['minimum_maximum_nights'].mean())\n",
        "test_df['maximum_maximum_nights'] = test_df['maximum_maximum_nights'].fillna(test_df['maximum_maximum_nights'].mean())\n",
        "test_df['minimum_nights_avg_ntm'] = test_df['minimum_nights_avg_ntm'].fillna(test_df['minimum_nights_avg_ntm'].mean())\n",
        "test_df['maximum_nights_avg_ntm'] = test_df['maximum_nights_avg_ntm'].fillna(test_df['maximum_nights_avg_ntm'].mean())\n",
        "test_df['has_availability'] = test_df['has_availability'].fillna(test_df['has_availability'].mode()[0])\n",
        "test_df['availability_30'] = test_df['availability_30'].fillna(test_df['availability_30'].mean())\n",
        "test_df['availability_60'] = test_df['availability_60'].fillna(test_df['availability_60'].mean())\n",
        "test_df['availability_90'] = test_df['availability_90'].fillna(test_df['availability_90'].mean())\n",
        "test_df['availability_365'] = test_df['availability_365'].fillna(test_df['availability_365'].mean())\n",
        "test_df['number_of_reviews'] = test_df['number_of_reviews'].fillna(test_df['number_of_reviews'].mean())\n",
        "test_df['number_of_reviews_ltm'] = test_df['number_of_reviews_ltm'].fillna(test_df['number_of_reviews_ltm'].mean())\n",
        "test_df['number_of_reviews_l30d'] = test_df['number_of_reviews_l30d'].fillna(test_df['number_of_reviews_l30d'].mean())\n",
        "test_df['review_scores_rating'] = test_df['review_scores_rating'].fillna(test_df['review_scores_rating'].mean())\n",
        "test_df['review_scores_accuracy'] = test_df['review_scores_accuracy'].fillna(test_df['review_scores_accuracy'].mean())\n",
        "test_df['review_scores_cleanliness'] = test_df['review_scores_cleanliness'].fillna(test_df['review_scores_cleanliness'].mean())\n",
        "test_df['review_scores_checkin'] = test_df['review_scores_checkin'].fillna(test_df['review_scores_checkin'].mean())\n",
        "test_df['review_scores_communication'] = test_df['review_scores_communication'].fillna(test_df['review_scores_communication'].mean())\n",
        "test_df['review_scores_location'] = test_df['review_scores_location'].fillna(test_df['review_scores_location'].mean())\n",
        "test_df['review_scores_value'] = test_df['review_scores_value'].fillna(test_df['review_scores_accuracy'].mean())\n",
        "test_df['instant_bookable'] = test_df['instant_bookable'].fillna(test_df['instant_bookable'].mode()[0])\n",
        "test_df['calculated_host_listings_count'] = test_df['calculated_host_listings_count'].fillna(test_df['calculated_host_listings_count'].mean())\n",
        "test_df['calculated_host_listings_count_entire_homes'] = test_df['calculated_host_listings_count_entire_homes'].fillna(test_df['calculated_host_listings_count_entire_homes'].mean())\n",
        "test_df['calculated_host_listings_count_private_rooms'] = test_df['calculated_host_listings_count_private_rooms'].fillna(test_df['calculated_host_listings_count_private_rooms'].mean())\n",
        "test_df['calculated_host_listings_count_shared_rooms'] = test_df['calculated_host_listings_count_shared_rooms'].fillna(test_df['calculated_host_listings_count_shared_rooms'].mean())\n",
        "test_df['reviews_per_month'] = test_df['reviews_per_month'].fillna(test_df['reviews_per_month'].mean())\n",
        "test_df['reviews_per_month'] = test_df['reviews_per_month'].fillna(test_df['reviews_per_month'].mean())\n",
        "test_df['price'] = test_df['price'].fillna(test_df['price'].mean())\n",
        "test_df['name_length'] = test_df['name_length'].fillna(test_df['name_length'].mean())\n",
        "test_df['desc_length'] = test_df['desc_length'].fillna(test_df['desc_length'].mean())\n",
        "test_df['neighborhood_overview_length'] = test_df['neighborhood_overview_length'].fillna(test_df['neighborhood_overview_length'].mean())\n",
        "test_df['host_about_length'] = test_df['host_about_length'].fillna(test_df['host_about_length'].mean())\n",
        "test_df['total_verification'] = test_df['total_verification'].fillna(test_df['total_verification'].mean())\n",
        "test_df['total_amenities'] = test_df['total_amenities'].fillna(test_df['total_amenities'].mean())\n",
        "test_df['number_of_days_as_host'] = test_df['number_of_days_as_host'].fillna(test_df['number_of_days_as_host'].mean())\n",
        "test_df['number_of_days_last_review'] = test_df['number_of_days_last_review'].fillna(test_df['number_of_days_last_review'].mean())\n",
        "test_df['number_of_days_first_review'] = test_df['number_of_days_first_review'].fillna(test_df['number_of_days_first_review'].mean())\n",
        "test_df['diff_in_last_&_first_review'] = test_df['diff_in_last_&_first_review'].fillna(test_df['diff_in_last_&_first_review'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y52YhqrCKNtM"
      },
      "outputs": [],
      "source": [
        "# Task 2, Question 4 Code Here\n",
        "# replacing 't' with 0 and 'f' with 1 in all of the below column for encoding categorical variable\n",
        "train_df['host_is_superhost'] = train_df['host_is_superhost'].apply(lambda x: 0 if x=='t' else 1)\n",
        "train_df['host_has_profile_pic'] = train_df['host_has_profile_pic'].apply(lambda x: 0 if x=='t' else 1)\n",
        "train_df['host_identity_verified'] = train_df['host_identity_verified'].apply(lambda x: 0 if x=='t' else 1)\n",
        "train_df['has_availability'] = train_df['has_availability'].apply(lambda x: 0 if x=='t' else 1)\n",
        "train_df['instant_bookable'] = train_df['instant_bookable'].apply(lambda x: 0 if x=='t' else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uicSY-gTKNvE"
      },
      "outputs": [],
      "source": [
        "# replacing 't' with 0 and 'f' with 1 in all of the below column for encoding categorical variable\n",
        "test_df['host_is_superhost'] = test_df['host_is_superhost'].apply(lambda x: 0 if x=='t' else 1)\n",
        "test_df['host_has_profile_pic'] = test_df['host_has_profile_pic'].apply(lambda x: 0 if x=='t' else 1)\n",
        "test_df['host_identity_verified'] = test_df['host_identity_verified'].apply(lambda x: 0 if x=='t' else 1)\n",
        "test_df['has_availability'] = test_df['has_availability'].apply(lambda x: 0 if x=='t' else 1)\n",
        "test_df['instant_bookable'] = test_df['instant_bookable'].apply(lambda x: 0 if x=='t' else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aKr_BuZhKNwm"
      },
      "outputs": [],
      "source": [
        "#One hot encoding for the categorical feature source\n",
        "vectorizer = CountVectorizer()\n",
        "train_source_ohe = vectorizer.fit_transform(train_df['source'].values)\n",
        "test_source_ohe = vectorizer.transform(test_df['source'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yycmn-IcKNy4"
      },
      "outputs": [],
      "source": [
        "#One hot encoding for the categorical feature host_name\n",
        "vectorizer = CountVectorizer()\n",
        "train_host_name_ohe = vectorizer.fit_transform(train_df['host_name'].values)\n",
        "test_host_name_ohe = vectorizer.transform(test_df['host_name'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_d2LbZLAKN0e"
      },
      "outputs": [],
      "source": [
        "#One hot encoding for the categorical feature  host location\n",
        "vectorizer = CountVectorizer()\n",
        "train_host_location_ohe = vectorizer.fit_transform(train_df['host_location'].values)\n",
        "test_host_location_ohe = vectorizer.transform(test_df['host_location'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qYnIy3t_KN2o"
      },
      "outputs": [],
      "source": [
        "# Fill NaN values in host_neighbourhood column\n",
        "train_df['host_neighbourhood'] = train_df['host_neighbourhood'].fillna('missing')\n",
        "test_df['host_neighbourhood'] = test_df['host_neighbourhood'].fillna('missing')\n",
        "\n",
        "# Apply CountVectorizer to host_neighbourhood column\n",
        "vectorizer = CountVectorizer()\n",
        "train_host_neighbourhood_ohe = vectorizer.fit_transform(train_df['host_neighbourhood'].values)\n",
        "test_host_neighbourhood_ohe = vectorizer.transform(test_df['host_neighbourhood'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Mdsmh4tmKN5Q"
      },
      "outputs": [],
      "source": [
        "#One hot encoding for the categorical feature host verifications\n",
        "vectorizer = CountVectorizer()\n",
        "train_host_verifications_ohe = vectorizer.fit_transform(train_df['host_verifications'].values)\n",
        "test_host_verifications_ohe = vectorizer.transform(test_df['host_verifications'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IR1kiYAPKN7d"
      },
      "outputs": [],
      "source": [
        "#One hot encoding for the categorical feature neighbourhood\n",
        "vectorizer = CountVectorizer()\n",
        "train_neighbourhood_ohe = vectorizer.fit_transform(train_df['neighbourhood'].values)\n",
        "test_neighbourhood_ohe = vectorizer.transform(test_df['neighbourhood'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WkldGXK4KN9i"
      },
      "outputs": [],
      "source": [
        "# Fill NaN values in host_response_time column\n",
        "train_df['host_response_time'] = train_df['host_response_time'].fillna('missing')\n",
        "test_df['host_response_time'] = test_df['host_response_time'].fillna('missing')\n",
        "\n",
        "# Apply CountVectorizer to host_response_time column\n",
        "vectorizer = CountVectorizer()\n",
        "train_host_response_time_ohe = vectorizer.fit_transform(train_df['host_response_time'].values)\n",
        "test_host_response_time_ohe = vectorizer.transform(test_df['host_response_time'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "inX6IW4aKN_0"
      },
      "outputs": [],
      "source": [
        "# Fill NaN values in neighbourhood_cleansed column\n",
        "train_df['neighbourhood_cleansed'] = train_df['neighbourhood_cleansed'].fillna('missing')\n",
        "test_df['neighbourhood_cleansed'] = test_df['neighbourhood_cleansed'].fillna('missing')\n",
        "\n",
        "# Apply CountVectorizer to neighbourhood_cleansed column\n",
        "vectorizer = CountVectorizer()\n",
        "train_neighbourhood_cleansed_ohe = vectorizer.fit_transform(train_df['neighbourhood_cleansed'].values)\n",
        "test_neighbourhood_cleansed_ohe = vectorizer.transform(test_df['neighbourhood_cleansed'].values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mvIzziW2KODF"
      },
      "outputs": [],
      "source": [
        "#One hot encoding for the categorical feature amenties\n",
        "vectorizer = CountVectorizer()\n",
        "train_amenities_ohe = vectorizer.fit_transform(train_df['amenities'].values)\n",
        "test_amenities_ohe = vectorizer.transform(test_df['amenities'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RoM7PqxJKOF0"
      },
      "outputs": [],
      "source": [
        "#cleaning text feature by removing stopwords and all the other character like html, puntuation etc\n",
        "\n",
        "# https://stackoverflow.com/a/47091490/4084039\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase\n",
        "\n",
        "\n",
        "# https://gist.github.com/sebleier/554280\n",
        "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
        "\n",
        "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "def preprocess_text(text_data):\n",
        "    preprocessed_text = []\n",
        "    # tqdm is for printing the status bar\n",
        "    for sentance in tqdm(text_data):\n",
        "        sent = decontracted(sentance)\n",
        "        sent = sent.replace('\\\\r', ' ')\n",
        "        sent = sent.replace('\\\\n', ' ')\n",
        "        sent = sent.replace('\\\\\"', ' ')\n",
        "        sent = sent.replace('()', '')\n",
        "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "        # https://gist.github.com/sebleier/554280\n",
        "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
        "        preprocessed_text.append(sent.lower().strip())\n",
        "    return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gcHtFjPhKOIF"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "def preprocess_text(text_data):\n",
        "    # Function to clean and preprocess text data\n",
        "    cleaned_data = []\n",
        "\n",
        "    # tqdm is for printing the status bar\n",
        "    for sentence in tqdm(text_data):\n",
        "        if isinstance(sentence, str):  # Check if the sentence is a string\n",
        "            sent = decontracted(sentence)\n",
        "            sent = sent.replace('\\\\r', ' ')\n",
        "            sent = sent.replace('\\\\n', ' ')\n",
        "            sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "            sent = ' '.join(e.lower() for e in sent.split() if e.lower() not in stopwords.words('english'))\n",
        "            cleaned_data.append(sent)\n",
        "        else:\n",
        "            cleaned_data.append('')  # Fill non-string values with an empty string\n",
        "\n",
        "    return cleaned_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1fzgYSLOXlj",
        "outputId": "435996bd-11a6-496d-9fa5-8c7bfb97f54b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALF2ayhEOXoW",
        "outputId": "56684bfc-792e-4ecf-e05f-b8b0cace1849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 7000/7000 [00:05<00:00, 1345.76it/s]\n",
            "100%|| 7000/7000 [02:45<00:00, 42.32it/s]\n",
            "100%|| 7000/7000 [00:44<00:00, 157.07it/s]\n",
            "100%|| 3000/3000 [00:03<00:00, 890.83it/s] \n",
            "100%|| 3000/3000 [00:49<00:00, 60.63it/s]\n",
            "100%|| 3000/3000 [00:12<00:00, 249.39it/s]\n"
          ]
        }
      ],
      "source": [
        "train_df['clean_name'] = preprocess_text(train_df['name']) #cleaning name feature for train dataset\n",
        "train_df['clean_desc'] = preprocess_text(train_df['description']) #cleaning description feature for train dataset\n",
        "train_df['clean_neighborhood_overview'] = preprocess_text(train_df['neighborhood_overview'])  #cleaning neighbourhood overview feature for train dataset\n",
        "\n",
        "test_df['clean_name'] = preprocess_text(test_df['name'])  #cleaning name feature for test dataset\n",
        "test_df['clean_desc'] = preprocess_text(test_df['description']) #cleaning description feature for test dataset\n",
        "test_df['clean_neighborhood_overview'] = preprocess_text(test_df['neighborhood_overview'])  #cleaning neighbourhood overview feature for test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pTL1q4anOXrI"
      },
      "outputs": [],
      "source": [
        "# implementing tfidf word vectorizer into name\n",
        "vectorizer = TfidfVectorizer(min_df=10)\n",
        "train_name_tfidf = vectorizer.fit_transform(train_df['clean_name'].values)\n",
        "test_name_tfidf = vectorizer.transform(test_df['clean_name'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lsCJP6wYOXtl"
      },
      "outputs": [],
      "source": [
        "# implementing tfidf word vectorizer into description\n",
        "vectorizer = TfidfVectorizer(min_df=10)\n",
        "train_desc_tfidf = vectorizer.fit_transform(train_df['clean_desc'].values)\n",
        "test_desc_tfidf = vectorizer.transform(test_df['clean_desc'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaXqKT_WOXwP",
        "outputId": "e3ca9df5-4fb6-4c28-c4db-9cfab4b5041b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 7000/7000 [00:58<00:00, 120.26it/s]\n",
            "100%|| 7000/7000 [01:07<00:00, 103.52it/s]\n",
            "100%|| 7000/7000 [01:03<00:00, 110.85it/s]\n",
            "100%|| 3000/3000 [00:26<00:00, 115.34it/s]\n",
            "100%|| 3000/3000 [00:26<00:00, 112.45it/s]\n",
            "100%|| 3000/3000 [00:26<00:00, 111.55it/s]\n"
          ]
        }
      ],
      "source": [
        "#Implementing NLTK sentimental intensity analyser on the clean preprocessed text feature\n",
        "def SID(text):  \n",
        "    ''' This function calculates the NLTK sentiments and return the negative, neutral, postive and compound values'''\n",
        "    negative = []\n",
        "    neutral = []\n",
        "    positive = []\n",
        "    compound = []\n",
        "    for lines in tqdm(text):\n",
        "      sid = SentimentIntensityAnalyzer()\n",
        "      sentiment_score = sid.polarity_scores(lines)\n",
        "    \n",
        "      negative.append(sentiment_score['neg'])\n",
        "      neutral.append(sentiment_score['neu'])\n",
        "      positive.append(sentiment_score['pos'])\n",
        "      compound.append(sentiment_score['compound'])\n",
        "    negative = np.asarray(negative).reshape(-1,1)\n",
        "    neutral = np.asarray(neutral).reshape(-1,1)\n",
        "    positive = np.asarray(positive).reshape(-1,1)\n",
        "    compound = np.asarray(compound).reshape(-1,1)\n",
        "    return negative, neutral, positive, compound\n",
        "\n",
        "train_name_neg, train_name_neu, train_name_pos, train_name_comp = SID(train_df['clean_name'].values) #for name feature\n",
        "train_desc_neg, train_desc_neu, train_desc_pos, train_desc_comp = SID(train_df['clean_desc'].values)  #for description feature\n",
        "train_neigh_over_neg, train_neigh_over_neu, train_neigh_over_pos, train_neigh_over_comp = SID(train_df['clean_neighborhood_overview'].values) #for neighbourhood overview feature\n",
        "\n",
        "test_name_neg, test_name_neu, test_name_pos, test_name_comp = SID(test_df['clean_name'].values) #for name feature\n",
        "test_desc_neg, test_desc_neu, test_desc_pos, test_desc_comp = SID(test_df['clean_desc'].values) #for name feature\n",
        "test_neigh_over_neg, test_neigh_over_neu, test_neigh_over_pos, test_neigh_over_comp = SID(test_df['clean_neighborhood_overview'].values) #for name feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "fwCg0NovOXyg"
      },
      "outputs": [],
      "source": [
        "## Task 2, Question 5 Code Here\n",
        "## scaling all the numerical data feature\n",
        "scale_list = ['name_length', 'desc_length', 'neighborhood_overview_length','bathrooms','host_about_length', 'total_verification', 'total_amenities','number_of_days_as_host','number_of_days_last_review' , 'number_of_days_first_review', 'diff_in_last_&_first_review','host_response_rate', 'host_acceptance_rate', 'latitude', 'longitude', 'maximum_nights','maximum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_nights_avg_ntm', 'availability_90', 'number_of_reviews', 'review_scores_rating','calculated_host_listings_count_private_rooms','calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_shared_rooms', 'reviews_per_month', 'calculated_host_listings_count', 'review_scores_value', 'review_scores_location', 'review_scores_communication', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_accuracy', 'review_scores_rating', 'number_of_reviews_l30d', 'number_of_reviews_ltm', 'availability_365', 'availability_90', 'availability_60', 'availability_30', 'maximum_nights_avg_ntm', 'minimum_nights_avg_ntm', 'maximum_minimum_nights', 'minimum_minimum_nights', 'maximum_nights', 'minimum_nights', 'host_listings_count']\n",
        "scale_list = list(set(scale_list))\n",
        "for col in scale_list:\n",
        "    scal = MinMaxScaler()\n",
        "    train_df[col] = scal.fit_transform(train_df[col].values.reshape(-1,1))\n",
        "    test_df[col] = scal.transform(test_df[col].values.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "g2SFA81OOX04"
      },
      "outputs": [],
      "source": [
        "#Task 3 code here\n",
        "#droping all the dataset\n",
        "drop_columns_list = ['source', 'host_name', 'host_location', 'price', 'host_about', 'host_neighbourhood', 'name', 'description', 'neighborhood_overview', 'clean_name', 'clean_desc', 'clean_neighborhood_overview', 'neighbourhood','host_response_time', 'neighbourhood_cleansed', 'host_verifications', 'property_type', 'room_type', 'amenities']\n",
        "\n",
        "Y = train_df['price']\n",
        "train_df = train_df.drop(drop_columns_list, axis=1)\n",
        "test_df = test_df.drop(drop_columns_list, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwW44idbOX3h",
        "outputId": "68a8d399-78d5-479e-95f7-fcd5badb1b55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for Linear Regression\n",
            "Best parameters for Linear Regression: {'fit_intercept': True}\n",
            "Scores for Linear Regression:\n",
            "RMSE: 2315.766251463929\n",
            "R^2: 0.008172298488895224\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "# Assuming your data is in pandas dataframes train_df and test_df\n",
        "X_train = train_df\n",
        "\n",
        "# Assuming target variable price is in variable Y\n",
        "y_train = Y\n",
        "\n",
        "X_test = test_df   # As you mentioned, test data doesn't have a 'price' column\n",
        "\n",
        "# Defining the model\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Defining parameter grids for grid search\n",
        "parameters_lr = {'fit_intercept': [True, False]}\n",
        "\n",
        "# Grid search for hyperparameter tuning\n",
        "print('Starting training for Linear Regression')\n",
        "grid_search = GridSearchCV(estimator=lr, param_grid=parameters_lr, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters\n",
        "print(f'Best parameters for Linear Regression: {grid_search.best_params_}')\n",
        "\n",
        "# Refit the model with best parameters\n",
        "lr = grid_search.best_estimator_\n",
        "\n",
        "# Predict the target for training data\n",
        "y_train_pred = lr.predict(X_train)\n",
        "\n",
        "# Accuracy scores\n",
        "rmse = sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "print(f'Scores for Linear Regression:')\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f'R^2: {r2}')\n",
        "\n",
        "# Predict on the test dataset\n",
        "y_test_pred = lr.predict(X_test)\n",
        "\n",
        "# Create a dataframe for output\n",
        "output_df = pd.DataFrame({\n",
        "    'ID': test_df['ID'],   # assuming the ID column in your test dataset is named 'ID'\n",
        "    'price': y_test_pred\n",
        "})\n",
        "\n",
        "# Save to a csv file\n",
        "output_df.to_csv('predictions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "VL6orWS3OX5x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from math import sqrt\n",
        "\n",
        "# Assuming your data is in pandas dataframes train_df and test_df\n",
        "X_train = train_df\n",
        "y_train = Y\n",
        "X_test = test_df   # As you mentioned, test data doesn't have a 'price' column\n",
        "\n",
        "# Defining the models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'SVR': SVR(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(),\n",
        "    'XGBRegressor': XGBRegressor(objective ='reg:squarederror')\n",
        "}\n",
        "\n",
        "# Defining parameter grids for grid search\n",
        "parameters = {\n",
        "    'Linear Regression': {'fit_intercept': [True, False]},\n",
        "    'SVR': {'kernel': ['linear', 'rbf'], 'C': [1, 10]},\n",
        "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]},\n",
        "    'Gradient Boosting': {'n_estimators': [100, 200], 'learning_rate': [0.1, 0.01, 0.001], 'max_depth': [3, 5, 7]},\n",
        "    'XGBRegressor': {'n_estimators': [100, 200], 'learning_rate': [0.1, 0.01, 0.001], 'max_depth': [3, 5, 7]}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a733qM0UPL5V",
        "outputId": "453e1600-f8ac-4c0c-887d-deae32d16a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for Linear Regression\n",
            "Best parameters for Linear Regression: {'fit_intercept': True}\n",
            "Scores for Linear Regression:\n",
            "RMSE: 2315.766251463929\n",
            "R^2: 0.008172298488895224\n",
            "Starting training for SVR\n"
          ]
        }
      ],
      "source": [
        "best_models = {}\n",
        "for model_name, model in models.items():\n",
        "    print(f'Starting training for {model_name}')\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=parameters[model_name], cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    \n",
        "    # Print best parameters\n",
        "    print(f'Best parameters for {model_name}: {grid_search.best_params_}')\n",
        "\n",
        "    # Refit the model with best parameters\n",
        "    model = grid_search.best_estimator_\n",
        "\n",
        "    # Predict the target for training data\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    \n",
        "    # Accuracy scores\n",
        "    rmse = sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "    r2 = r2_score(y_train, y_train_pred)\n",
        "    \n",
        "    print(f'Scores for {model_name}:')\n",
        "    print(f'RMSE: {rmse}')\n",
        "    print(f'R^2: {r2}')\n",
        "    \n",
        "    best_models[model_name] = model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyB5n6d-UP6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7nYqleKUQL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DzWraZxXURBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1NBx614NESEFkbupEqHU1zaEcJOI3-F1I",
      "authorship_tag": "ABX9TyMx44UdV2BjPi4FgGvRedVj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}